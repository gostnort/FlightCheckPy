#!/usr/bin/env python3
"""
Data Cleaning Utility for HBPR Processing
åœ¨æ•°æ®è¾“å…¥å’Œå­˜å‚¨é˜¶æ®µæ¸…ç†é—®é¢˜å­—ç¬¦ï¼Œé˜²æ­¢å¯¼å‡ºé”™è¯¯
"""

import re
import logging
from typing import List, Tuple, Optional


# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def clean_text_for_input(text: str, aggressive: bool = False) -> str:
    """
    æ¸…ç†è¾“å…¥æ–‡æœ¬ï¼Œç§»é™¤æˆ–æ›¿æ¢é—®é¢˜å­—ç¬¦
    Args:
        text (str): åŸå§‹æ–‡æœ¬
        aggressive (bool): æ˜¯å¦ä½¿ç”¨æ¿€è¿›çš„æ¸…ç†æ¨¡å¼ï¼ˆç§»é™¤æ›´å¤šå­—ç¬¦ï¼‰
    Returns:
        str: æ¸…ç†åçš„æ–‡æœ¬
    """
    if not text or not isinstance(text, str):
        return ""
    
    original_text = text
    cleaned = text
    # è¿™äº›å­—ç¬¦åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹éƒ½æ˜¯æœ‰å®³çš„
    # å¤„ç†ASCIIæ§åˆ¶å­—ç¬¦ï¼Œä½†ä¿ç•™CR(\r)å’ŒLF(\n)å’ŒTAB(\t)
    cleaned = re.sub(r'[\x00-\x09]', ' ', cleaned)  # 0-9 (ä¿ç•™LF \x0a)
    cleaned = re.sub(r'[\x0b\x0c]', ' ', cleaned)  # 11-12 (ä¿ç•™TAB \x09)
    cleaned = re.sub(r'[\x0e-\x1f]', ' ', cleaned)  # 14-31 (ä¿ç•™CR \x0d)
    cleaned = re.sub(r'[\x7f]', ' ', cleaned)  # DELå­—ç¬¦
 
    
    # è®°å½•æ¸…ç†æƒ…å†µ
    if cleaned != original_text:
        logger.info(f"Text cleaned: {len(original_text)} -> {len(cleaned)} characters")
        # è®°å½•è¢«ç§»é™¤çš„å­—ç¬¦ç±»å‹
        removed_chars = set(original_text) - set(cleaned)
        if removed_chars:
            logger.info(f"Removed character types: {[repr(c) for c in sorted(removed_chars)]}")
    
    return cleaned


def clean_hbpr_record_content(content: str) -> str:
    """
    ä¸“é—¨æ¸…ç†HBPRè®°å½•å†…å®¹
    Args:
        content (str): HBPRè®°å½•å†…å®¹
    Returns:
        str: æ¸…ç†åçš„å†…å®¹
    """
    if not content:
        return content
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ§åˆ¶å­—ç¬¦
    has_control_chars = re.search(r'[\x00-\x1f\x7f]', content)
    has_binary_chars = re.search(r'[^\x20-\x7e\n\r\t]', content)
    
    if has_control_chars or has_binary_chars:
        logger.warning("HBPR content contains control or binary characters, cleaning...")
        return clean_text_for_input(content, aggressive=True)
    
    return content


def validate_and_clean_file_content(file_path: str, encoding: str = 'utf-8') -> Tuple[List[str], bool]:
    """
    éªŒè¯å¹¶æ¸…ç†æ–‡ä»¶å†…å®¹
    Args:
        file_path (str): æ–‡ä»¶è·¯å¾„
        encoding (str): æ–‡ä»¶ç¼–ç 
    Returns:
        Tuple[List[str], bool]: (æ¸…ç†åçš„è¡Œåˆ—è¡¨, æ˜¯å¦è¿›è¡Œäº†æ¸…ç†)
    """
    try:
        # å°è¯•æ­£å¸¸è¯»å–
        with open(file_path, 'r', encoding=encoding) as file:
            lines = file.readlines()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
        needs_cleaning = False
        cleaned_lines = []
        
        for i, line in enumerate(lines):
            original_line = line
            cleaned_line = clean_text_for_input(line)
            
            if cleaned_line != original_line:
                needs_cleaning = True
                logger.info(f"Line {i+1} cleaned: {len(original_line)} -> {len(cleaned_line)} characters")
            
            cleaned_lines.append(cleaned_line)
        
        if needs_cleaning:
            logger.warning(f"File {file_path} contained problematic characters and has been cleaned")
        
        return cleaned_lines, needs_cleaning
        
    except UnicodeDecodeError as e:
        logger.error(f"Unicode decode error in {file_path}: {e}")
        # å°è¯•ä½¿ç”¨errors='replace'æ¨¡å¼
        try:
            with open(file_path, 'r', encoding=encoding, errors='replace') as file:
                lines = file.readlines()
            
            # å¼ºåˆ¶æ¸…ç†æ‰€æœ‰è¡Œ
            cleaned_lines = [clean_text_for_input(line, aggressive=True) for line in lines]
            logger.warning(f"File {file_path} decoded with replacement and cleaned")
            return cleaned_lines, True
            
        except Exception as e2:
            logger.error(f"Failed to read file {file_path} even with replacement: {e2}")
            raise
    
    except Exception as e:
        logger.error(f"Error reading file {file_path}: {e}")
        raise


def clean_database_content_before_save(content: str, field_name: str = "unknown") -> str:
    """
    åœ¨ä¿å­˜åˆ°æ•°æ®åº“å‰æ¸…ç†å†…å®¹
    Args:
        content (str): è¦ä¿å­˜çš„å†…å®¹
        field_name (str): å­—æ®µåç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    Returns:
        str: æ¸…ç†åçš„å†…å®¹
    """
    if not content:
        return content
    
    original_content = content
    cleaned_content = clean_text_for_input(content)
    
    if cleaned_content != original_content:
        logger.info(f"Field '{field_name}' cleaned before database save: {len(original_content)} -> {len(cleaned_content)} characters")
    
    return cleaned_content


def batch_clean_text_data(text_list: List[str], field_name: str = "unknown") -> List[str]:
    """
    æ‰¹é‡æ¸…ç†æ–‡æœ¬æ•°æ®
    Args:
        text_list (List[str]): æ–‡æœ¬åˆ—è¡¨
        field_name (str): å­—æ®µåç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    Returns:
        List[str]: æ¸…ç†åçš„æ–‡æœ¬åˆ—è¡¨
    """
    if not text_list:
        return text_list
    
    cleaned_list = []
    cleaned_count = 0
    
    for i, text in enumerate(text_list):
        if text:
            original_text = text
            cleaned_text = clean_text_for_input(text)
            if cleaned_text != original_text:
                cleaned_count += 1
            cleaned_list.append(cleaned_text)
        else:
            cleaned_list.append(text)
    
    if cleaned_count > 0:
        logger.info(f"Batch cleaned {cleaned_count} out of {len(text_list)} items in field '{field_name}'")
    
    return cleaned_list


def get_cleaning_statistics(text: str) -> dict:
    """
    è·å–æ–‡æœ¬æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
    Args:
        text (str): åŸå§‹æ–‡æœ¬
    Returns:
        dict: æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
    """
    if not text:
        return {"total_chars": 0, "control_chars": 0, "binary_chars": 0, "needs_cleaning": False}
    
    stats = {
        "total_chars": len(text),
        "control_chars": len(re.findall(r'[\x00-\x1f\x7f]', text)),
        "binary_chars": len(re.findall(r'[^\x20-\x7e\n\r\t]', text)),
        "needs_cleaning": False
    }
    
    stats["needs_cleaning"] = stats["control_chars"] > 0 or stats["binary_chars"] > 0
    
    return stats


def preview_cleaning_effect(text: str, max_length: int = 100) -> dict:
    """
    é¢„è§ˆæ¸…ç†æ•ˆæœ
    Args:
        text (str): åŸå§‹æ–‡æœ¬
        max_length (int): æœ€å¤§æ˜¾ç¤ºé•¿åº¦
    Returns:
        dict: æ¸…ç†é¢„è§ˆä¿¡æ¯
    """
    if not text:
        return {"original": "", "cleaned": "", "changed": False}
    
    cleaned = clean_text_for_input(text)
    changed = cleaned != text
    
    # æˆªæ–­æ˜¾ç¤º
    original_preview = text[:max_length] + ("..." if len(text) > max_length else "")
    cleaned_preview = cleaned[:max_length] + ("..." if len(cleaned) > max_length else "")
    
    return {
        "original": original_preview,
        "cleaned": cleaned_preview,
        "changed": changed,
        "original_length": len(text),
        "cleaned_length": len(cleaned),
        "statistics": get_cleaning_statistics(text)
    }


if __name__ == "__main__":
    # æµ‹è¯•åŠŸèƒ½
    test_cases = [
        "Normal text",
        "Text with \x00\x01\x02 control chars",
        "Text with \x7f DEL char",
        ">HBPR: CA984/15AUG25*LAX,67 PNR RL MZBX",
        "Mixed: >HBPR: CA984/15AUG25*LAX,67 PNR RL MZBX with \x1f\x1e\x1d control chars"
    ]
    
    print("ğŸ§ª Testing Data Cleaning Utility")
    print("=" * 50)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nTest {i}:")
        preview = preview_cleaning_effect(test_case)
        print(f"  Original: {preview['original']}")
        print(f"  Cleaned:  {preview['cleaned']}")
        print(f"  Changed:   {preview['changed']}")
        print(f"  Length:    {preview['original_length']} -> {preview['cleaned_length']}")
        print(f"  Stats:     {preview['statistics']}")
    
    print("\nğŸ‰ Testing completed!")
