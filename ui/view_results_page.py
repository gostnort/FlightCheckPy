#!/usr/bin/env python3
"""
View Results page for HBPR UI - Results analysis and export interface
"""

import streamlit as st
import pandas as pd
import os
import sqlite3
import re
from datetime import datetime
from io import BytesIO
from scripts.hbpr_info_processor import HbprDatabase
from scripts.command_processor import CommandProcessor
from ui.common import apply_global_settings, get_current_database


def show_view_results():
    """æ˜¾ç¤ºç»“æœæŸ¥çœ‹é¡µé¢"""
    # Apply settings
    apply_global_settings()
    try:
        # è·å–å½“å‰é€‰ä¸­çš„æ•°æ®åº“
        selected_db_file = get_current_database()
        
        if not selected_db_file:
            st.error("âŒ No database selected.")
            st.info("ğŸ’¡ Please select a database from the sidebar or build one first in the Database Management page.")
            return
        
        db = HbprDatabase(selected_db_file)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è½¬åˆ°ç‰¹å®šæ ‡ç­¾é¡µ
        default_tab = 0  # é»˜è®¤æ˜¾ç¤ºStatisticsæ ‡ç­¾é¡µ
        if hasattr(st.session_state, 'view_results_tab'):
            if st.session_state.view_results_tab == "ğŸ“‹ Sort Records":
                default_tab = 1  # Sort Recordsæ ‡ç­¾é¡µ
            elif st.session_state.view_results_tab == "ğŸ“¤ Export Data":
                default_tab = 2  # Export Dataæ ‡ç­¾é¡µ
            # æ¸…é™¤session stateä¸­çš„æ ‡ç­¾é¡µè®¾ç½®
            del st.session_state.view_results_tab
        
        tab1, tab2 = st.tabs(["ğŸ“‹ Sort Records", "ğŸ“¤ Export Data"])
        
        with tab1:
            show_records_table(db)
        
        with tab2:
            show_export_options(db)
    
    except Exception as e:
        st.error(f"âŒ Database not available: {str(e)}")
        st.info("ğŸ’¡ Please select a database from the sidebar or build one first in the Database Management page.")



def show_records_table(db):
    """æ˜¾ç¤ºè®°å½•è¡¨æ ¼"""
    st.subheader("ğŸ“‹ Processed Records")
    
    try:
        conn = sqlite3.connect(db.db_file)
        
        # æŸ¥è¯¢å·²å¤„ç†çš„è®°å½•ï¼ŒåŒ…æ‹¬propertiesã€ckin_msgå’Œasvc_msgå­—æ®µ
        df = pd.read_sql_query("""
            SELECT hbnb_number, boarding_number, name, seat, class, destination,
                   bag_piece, bag_weight, ff, ckin_msg, properties, asvc_msg, error_count
            FROM hbpr_full_records 
            WHERE is_validated = 1
            ORDER BY hbnb_number
        """, conn)
        conn.close()
        
        if df.empty:
            st.info("â„¹ï¸ No processed records found.")
            return
        
        # æå–FF Levelï¼ˆä»FFå­—æ®µä¸­æå–æœ€åçš„å­—æ¯ï¼‰
        def extract_ff_level(ff_value):
            if pd.isna(ff_value) or ff_value == '':
                return 'N/A'
            # æå–FFå·ç æœ€åçš„å­—æ¯ï¼Œå¦‚ "CA 050021619897/B" -> "B"
            parts = ff_value.split('/')
            if len(parts) > 1:
                return parts[-1]
            return 'N/A'

        # æ·»åŠ FF Levelåˆ—
        df['ff_level'] = df['ff'].apply(extract_ff_level)
        
        # æå–CKINç±»å‹ï¼ˆä»CKIN_MSGä¸­æå–æ‰€æœ‰CKINç±»å‹ï¼‰
        def extract_ckin_type(ckin_msg):
            if pd.isna(ckin_msg) or ckin_msg == '':
                return ''
            # åˆ†å‰²CKINæ¶ˆæ¯å¹¶æå–æ‰€æœ‰CKINç±»å‹
            ckin_list = [msg.strip() for msg in ckin_msg.split(';') if msg.strip()]
            ckin_types = []
            for ckin_msg_item in ckin_list:
                # åŒ¹é… CKIN åè·Ÿ 4ä¸ªå­—æ¯æ•°å­—å­—ç¬¦ï¼Œç„¶åæ˜¯éæ•°å­—å­—ç¬¦
                match = re.search(r'CKIN\s+([A-Z0-9]{4})[^0-9]', ckin_msg_item)
                if match:
                    ckin_types.append(match.group(1))
            return ckin_types

        # æ·»åŠ CKINç±»å‹åˆ—ï¼ˆåŒ…å«æ‰€æœ‰CKINç±»å‹ï¼Œç”¨é€—å·åˆ†éš”ï¼‰
        df['ckin_types'] = df['ckin_msg'].apply(lambda x: ', '.join(extract_ckin_type(x)) if extract_ckin_type(x) else '')
        
        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„CKINç±»å‹ç”¨äºè¿‡æ»¤å™¨
        all_ckin_types = set()
        for ckin_types_str in df['ckin_types'].dropna():
            if ckin_types_str != '':
                types_list = [t.strip() for t in ckin_types_str.split(',') if t.strip()]
                all_ckin_types.update(types_list)
        
        # è¿‡æ»¤é€‰é¡¹
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            filter_class = st.multiselect("Filter by Class:", df['class'].dropna().unique())
        
        with col2:
            # FF Levelè¿‡æ»¤å™¨
            ff_levels = sorted(df['ff_level'].dropna().unique())
            filter_ff_level = st.multiselect("Filter by FF Level:", ff_levels)
        
        with col3:
            # CKINç±»å‹è¿‡æ»¤å™¨
            available_ckin_types = sorted(list(all_ckin_types))
            filter_ckin_type = st.multiselect("Filter by CKIN Type:", available_ckin_types)
        
        with col4:
            # Propertiesè¿‡æ»¤å™¨ - æ›¿æ¢destinationè¿‡æ»¤å™¨
            # ä»propertieså­—æ®µä¸­æå–æ‰€æœ‰å”¯ä¸€çš„å±æ€§
            all_properties = set()
            for properties_str in df['properties'].dropna():
                if properties_str:
                    properties_list = [prop.strip() for prop in properties_str.split(',') if prop.strip()]
                    all_properties.update(properties_list)
            
            available_properties = sorted(list(all_properties))
            filter_properties = st.multiselect("Filter by Properties:", available_properties)
        
        # åº”ç”¨è¿‡æ»¤å™¨
        filtered_df = df.copy()
        
        if filter_class:
            filtered_df = filtered_df[filtered_df['class'].isin(filter_class)]
        
        if filter_ff_level:
            filtered_df = filtered_df[filtered_df['ff_level'].isin(filter_ff_level)]
        
        if filter_ckin_type:
            # è¿‡æ»¤åŒ…å«é€‰å®šCKINç±»å‹çš„è®°å½•
            def has_ckin_type(ckin_types_str, target_ckin_types):
                if pd.isna(ckin_types_str) or ckin_types_str == '':
                    return False
                types_list = [t.strip() for t in ckin_types_str.split(',') if t.strip()]
                return any(ckin_type in types_list for ckin_type in target_ckin_types)
            
            filtered_df = filtered_df[filtered_df['ckin_types'].apply(
                lambda x: has_ckin_type(x, filter_ckin_type)
            )]
        
        if filter_properties:
            # è¿‡æ»¤åŒ…å«é€‰å®šå±æ€§çš„è®°å½•
            def has_property(properties_str, target_properties):
                if pd.isna(properties_str) or properties_str == '':
                    return False
                properties_list = [prop.strip() for prop in properties_str.split(',') if prop.strip()]
                return any(prop in properties_list for prop in target_properties)
            
            filtered_df = filtered_df[filtered_df['properties'].apply(
                lambda x: has_property(x, filter_properties)
            )]
        
        # æ˜¾ç¤ºè¡¨æ ¼ï¼ˆä¸æ˜¾ç¤ºff_levelå’Œckin_typesåˆ—ï¼Œå› ä¸ºå®ƒä»¬åªæ˜¯ç”¨äºè¿‡æ»¤ï¼‰
        display_df = filtered_df.drop(columns=['ff_level', 'ckin_types'])
        
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True,  # éšè—è‡ªåŠ¨åºåˆ—å·
            column_config={
                "hbnb_number": st.column_config.NumberColumn("HBNB", format="%d"),
                "boarding_number": st.column_config.NumberColumn("BN", format="%d"),
                "name": "Name",
                "seat": "Seat",
                "class": "Class",
                "destination": "Destination", 
                "bag_piece": st.column_config.NumberColumn("Bag Pieces", format="%d"),
                "bag_weight": st.column_config.NumberColumn("Bag Weight", format="%d kg"),
                "ff": "FF Number",
                "properties": "Properties",
                "ckin_msg": st.column_config.TextColumn("CKIN Messages", max_chars=100),
                "asvc_msg": st.column_config.TextColumn("ASVC Messages", max_chars=100),
                "error_count": st.column_config.NumberColumn("Errors", format="%d")
            }
        )
        
        st.info(f"ğŸ“Š Showing {len(filtered_df)} of {len(df)} records")
    
    except Exception as e:
        st.error(f"âŒ Error loading records: {str(e)}")


def export_as_origin_txt(db_file: str) -> str:
    """
    å¯¼å‡ºåŸå§‹æ–‡æœ¬æ ¼å¼ï¼ŒåŒ…å«full_recordè¡¨çš„record_contentå’Œcommandsè¡¨çš„command_typeã€command_full
    Args:
        db_file (str): æ•°æ®åº“æ–‡ä»¶è·¯å¾„   
    Returns:
        str: æ ¼å¼åŒ–çš„åŸå§‹æ–‡æœ¬å†…å®¹
    """
    content_parts = []
    try:
        conn = sqlite3.connect(db_file)
        
        # å¯¼å‡ºfull_recordè¡¨çš„record_content
        cursor = conn.execute("""
            SELECT hbnb_number, record_content 
            FROM hbpr_full_records 
            ORDER BY hbnb_number
        """)
        full_records = cursor.fetchall()
        if full_records:
            for hbnb_number, record_content in full_records:
                content_parts.append(record_content)
                content_parts.append("")
        # å¯¼å‡ºcommandsè¡¨çš„command_typeå’Œcommand_full
        cursor = conn.execute("""
            SELECT command_full, content
            FROM commands 
            ORDER BY command_full, content
        """)
        
        commands = cursor.fetchall()
        if commands:
            for command_full, content in commands:
                content_parts.append(f">{command_full}\n{content}")
                content_parts.append("")
        
        conn.close()
        
        return "\n".join(content_parts)
        
    except Exception as e:
        return f"Error exporting data: {str(e)}"


def show_export_options(db):
    """æ˜¾ç¤ºå¯¼å‡ºé€‰é¡¹"""
    st.subheader("ğŸ“¤ Export Data")
    
    try:
        conn = sqlite3.connect(db.db_file)
        
        # è·å–æ‰€æœ‰å·²å¤„ç†çš„è®°å½•
        df = pd.read_sql_query("""
            SELECT * FROM hbpr_full_records 
            WHERE is_validated = 1
            ORDER BY hbnb_number
        """, conn)
        
        conn.close()
        
        if df.empty:
            st.info("â„¹ï¸ No processed records to export.")
            return
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # CSVå¯¼å‡º
            csv_data = df.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ Download as CSV",
                data=csv_data,
                file_name=f"hbpr_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col2:
            # Excelå¯¼å‡º
            excel_buffer = BytesIO()
            df.to_excel(excel_buffer, index=False, engine='openpyxl')
            excel_data = excel_buffer.getvalue()
            st.download_button(
                label="ğŸ“Š Download as Excel",
                data=excel_data,
                file_name=f"hbpr_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        
        with col3:
            # åŸå§‹æ–‡æœ¬å¯¼å‡º
            origin_txt_data = export_as_origin_txt(db.db_file)
            st.download_button(
                label="ğŸ“„ Download as Orig Txt",
                data=origin_txt_data,
                file_name=f"origin_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                use_container_width=True
            )
        
        # æ˜¾ç¤ºå¯¼å‡ºé¢„è§ˆ
        st.subheader("ğŸ‘€ Export Preview")
        st.dataframe(df.head(10), use_container_width=True)
        st.info(f"ğŸ“Š Total records ready for export: {len(df)}")
    except Exception as e:
        st.error(f"âŒ Error preparing export: {str(e)}")